# cbf_service.py
import mysql.connector
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from typing import List, Dict, Union


class CBFSystemNormalizedProximity:
    def __init__(
        self,
        scores_data: Union[pd.DataFrame, List[Dict]],
        passing_data: Union[pd.DataFrame, List[Dict]],
        tolerance: float = 0.1,
    ):
        # pastikan dataframe
        self.df_scores = (
            pd.DataFrame(scores_data)
            if not isinstance(scores_data, pd.DataFrame)
            else scores_data.copy()
        )
        self.df_passing = (
            pd.DataFrame(passing_data)
            if not isinstance(passing_data, pd.DataFrame)
            else passing_data.copy()
        )
        self.tolerance = tolerance

        # pastikan kolom skor numerik
        self.score_cols = [c for c in self.df_scores.columns if c != "id_user"]
        self.df_scores[self.score_cols] = self.df_scores[self.score_cols].apply(
            pd.to_numeric, errors="coerce"
        ).fillna(0)

        # hitung rata-rata skor umum
        self.df_scores["avg_score"] = self.df_scores[self.score_cols].mean(axis=1)
        self.feature_matrix = self.df_scores[self.score_cols].to_numpy(dtype=float)

        # pastikan kolom passing grade numerik
        for col in ["rataan", "min_val", "max_val"]:
            if col in self.df_passing.columns:
                self.df_passing[col] = pd.to_numeric(
                    self.df_passing[col], errors="coerce"
                ).fillna(0)

    def recommend(
        self,
        user_id: int,
        top_n_user: int = 5,
        top_n_prodi: int = 10,
        weight_tps: float = 0.3,
        weight_mapel: float = 0.7,
    ) -> pd.DataFrame:
        """
        Gabungan: cari user mirip → rekomendasi prodi.
        """
        if user_id not in self.df_scores["id_user"].values:
            return pd.DataFrame()

        # =======================
        # 1. Cari user mirip
        # =======================
        idx = self.df_scores.index[self.df_scores["id_user"] == user_id][0]
        user_vector = self.feature_matrix[idx].reshape(1, -1)

        similarities = cosine_similarity(user_vector, self.feature_matrix).flatten()
        similarities[idx] = -1  # hindari dirinya sendiri
        similarities = np.clip(similarities, 0, 1)

        top_indices = similarities.argsort()[::-1][:top_n_user]
        sim_df = self.df_scores.loc[top_indices, ["id_user", "avg_score"]].copy()
        sim_df["similarity"] = similarities[top_indices]
        sim_df["query_user_id"] = user_id

        if sim_df.empty:
            return pd.DataFrame()

        # =======================
        # 2. Ambil data user utama
        # =======================
        user_row = self.df_scores.iloc[idx]

        # Pisahkan TPS vs Mapel
        tps_cols = [
            c
            for c in self.score_cols
            if c in ["score_kmb", "score_kpu", "score_kua", "score_ppu"]
        ]
        mapel_cols = [c for c in self.score_cols if c not in tps_cols]

        tps_score = user_row[tps_cols].mean() if tps_cols else 0
        mapel_score = user_row[mapel_cols].mean() if mapel_cols else 0
        user_avg_weighted = (weight_tps * tps_score) + (weight_mapel * mapel_score)

        # =======================
        # 3. Gabungkan dengan passing grade
        # =======================
        merged = sim_df.merge(self.df_passing, how="cross")

        # Filter: avg_score minimal min_val
        merged = merged[merged["avg_score"] >= merged["min_val"]]

        # Filter: avg_score dalam range rataan ± tolerance
        merged = merged[
            (merged["avg_score"] >= merged["rataan"] * (1 - self.tolerance))
            & (merged["avg_score"] <= merged["rataan"] * (1 + self.tolerance))
        ]

        if merged.empty:
            return pd.DataFrame()

        # =======================
        # 4. Scoring
        # =======================
        merged["user_avg_score"] = user_avg_weighted

        # Normalisasi relatif terhadap min-max passing grade
        merged["score_rel"] = (merged["avg_score"] - merged["min_val"]) / (
            merged["max_val"] - merged["min_val"]
        )
        merged["score_rel"] = merged["score_rel"].clip(0, 1)

        # Skor akhir = similarity × passing grade × skor relatif
        merged["score"] = merged["similarity"] * merged["rataan"] * merged["score_rel"]

        # Normalisasi ke 0–100
        max_score = merged["score"].max()
        merged["recommendation_score"] = (
            (merged["score"] / max_score * 100).round(2) if max_score > 0 else 0
        )

        # Tambahkan probabilitas diterima
        merged["acceptance_probability"] = (
            1 / (1 + np.exp(-0.1 * (merged["recommendation_score"] - 50)))
        ).round(4)
        merged["acceptance_probability"] = (
            merged["acceptance_probability"] * 100
        ).round(2)

        # =======================
        # 5. Urutkan hasil
        # =======================
        merged = merged.sort_values(
            by="recommendation_score", ascending=False
        ).reset_index(drop=True)

        return merged.head(top_n_prodi)[
            [
                "id_user",
                "avg_score",
                "similarity",
                "nama_prodi",
                "name_university",   # ✅ tambahkan kolom universitas
                "rataan",
                "min_val",
                "max_val",
                "score_rel",
                "score",
                "recommendation_score",
                "acceptance_probability",
            ]
        ]


# ======================
# Contoh penggunaan dari MySQL
# ======================
if __name__ == "__main__":
    conn = mysql.connector.connect(
        host="localhost",
        user="root",
        password="Astagfirullah123#",
        database="rekomendasi_perkuliahan",
    )

    df_science = pd.read_sql("SELECT * FROM science_scores", conn)
    df_passing_grade = pd.read_sql(
        "SELECT * FROM passing_grade WHERE type='science'", conn
    )
    conn.close()

    cbf = CBFSystemNormalizedProximity(df_science, df_passing_grade)

    recommendations = cbf.recommend(user_id=20, top_n_user=5, top_n_prodi=10)
    
    recommendations.to_csv("recommendations_science.csv", index=False)

    print(recommendations)
    
    












